<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Training</title>
</head>
<body>
    </style><link rel="stylesheet" href="style.css">

    <h1 style="text-align:center">P.SAMD</h1>

    <!-- Horizontal menu -->
    <div class="navbar">
        <a href="index.html">Home</a>
        <a href="dbs.html">Databases</a>
        <a href="model.html">Model</a>
        <a href="training.html" class="active">Training</a>
        <a href="performance.html">Performance</a>
    </div>

    <h1 style="text-align:center">Training</h1>

    <div>
        <h2><u>Input</u></h2>
        <p>Note: Gabriel normalised the MOS scores. "Speech quality ratings are often subject 
            to a database specific bias. Because of this, we normalize each database by setting 
            the MOS value of the clean reference condition to MOS=4.75 with the following formula 
            (thus, effectively assuming a linear bias): MOS_(norm,i)= (MOS_i-1)/(MOS_max-1) 3.75+1.
            So, should we also normalize the MOS values before tzraining? Or validating, or testing?
            </p>
    </div>

    <div>
        <h2><u>Output</u></h2>
        <p>Note: Gabriel focused on reporting 3 metric scores: RMSE (1st and 3rd oder polynomial 
            mapping) and PCC (without mapping) calculated per condition and not per file. 
            So, should we consider this for loss calculation for backpropagation?
        </p>
    </div>

    <div>
        <h2><u>Notes</u></h2>
        <p>Work Item ITU-T P.MLGuide mentioned in at least the Report of the meeting of Working Party 2/12 
            (Geneva, 26 Nov - 4 Dec 2019).
        </p>
    </div>
    

        
</body>
</html>